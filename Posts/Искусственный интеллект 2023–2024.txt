Искусственный интеллект 2023–2024: борьба за данные и открытая разработка


По мнению экспертов, именно стартапы, занимающиеся разработкой генеративных нейросетей, не позволили упасть рынку венчурного капитала. На фоне падения оценочной стоимости IT-компаний стартапы сосредоточились на ИИ-приложениях и привлекли более $18 млрд. В 2023 году корпорации также переориентировали свои инвестиции на генеративный ИИ. Одновременно они сократили вложения в компании, не связанные с искусственным интеллектом, на 50% в годовом выражении. Инвестиции в ИИ же сохраняют стабильность — $29 млрд в 2022 году против $22 млрд в 2023-м.

Одновременно растет интерес обычных людей к взаимодействию с чат-ботами. Так, стартап Character.AI, который привлек $150 млн в первом раунде финансирования, сообщил о 200 млн ежемесячных пользователей своего приложения. Платформа Discord, которая интегрировала нейросеть Midjourney для генерации изображений, заявляла, что каждый месяц приложением пользуются около 30 млн человек, которые создают более 1 млрд уникальных изображений.

Методы обучения ИИ исчерпали себя
Как отмечают эксперты, модель GPT-4 от OpenAI смогла превзойти другие нейросети — как по классическим тестам для ИИ, так и по итогам экзаменов для оценки способностей человека. Кроме того, модель подтвердила эффективность метода обучения с подкреплением на основе отзывов людей (reinforcement learning from human feedback, RLHF). Однако этот метод требует найма персонала для оценки и ранжирования результатов модели, а также моделирования предпочтений, что делает эту технику сложной, дорогой и предвзятой. Это побудило исследователей искать альтернативы. Так, команда из Университета Беркли уже продемонстрировала, как точная настройка небольших языковых моделей (small language models, SLM) на основе результатов более крупных языковых моделей (large language models, LLM) позволяет создавать более стилистически богатые тексты, но и с более низкой точностью ответов. В связи с этим исследователи предлагают метод обучения, основанный на предварительной оценке входных данных.

Однако в ближайшее время метод обучения с подкреплением продолжит лидировать в сфере ИИ, уверены эксперты. Вероятно, компании будут улучшать его путем выпуска моделей меньшего размера и лучших наборов заранее отсортированных и проверенных людьми данных.

Еще одна проблема в обучении ИИ связана с тем, что уже к 2025 году запас открытых данных может закончиться. Как уточняют исследователи из Epoch AI, запас языковых данных высокого качества будет исчерпан к 2026 году, а низкого — к 2030–2050 годам. По мнению авторов отчета, после этого разработчики ИИ начнут использовать датасеты компаний для обучения моделей, а также будут активнее применять в этих целях сгенерированный контент.



